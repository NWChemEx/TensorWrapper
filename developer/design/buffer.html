<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Designing the Buffer &mdash; TensorWrapper 1.0.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Designing TensorWrapper Class" href="tensor_wrapper.html" />
    <link rel="prev" title="Designing the Allocator" href="allocator.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.0.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../background/index.html">TensorWrapper Background</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Developer Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Design of TensorWrapper</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="motivation.html">Motivating TensorWrapper</a></li>
<li class="toctree-l3"><a class="reference internal" href="overview.html">Overview of TensorWrapper</a></li>
<li class="toctree-l3"><a class="reference internal" href="shape.html">Tensor Shape Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="symmetry.html">Designing the Symmetry Component</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparsity.html">Tensor Sparsity Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="layout.html">Designing the Layout Component</a></li>
<li class="toctree-l3"><a class="reference internal" href="allocator.html">Designing the Allocator</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Designing the Buffer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#what-is-the-buffer">What is the Buffer?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#why-do-we-need-a-buffer">Why do we need a Buffer?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#buffer-terminology">Buffer Terminology</a></li>
<li class="toctree-l4"><a class="reference internal" href="#buffer-considerations">Buffer Considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#buffer-design">Buffer Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="#proposed-apis">Proposed APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tensor_wrapper.html">Designing <code class="docutils literal notranslate"><span class="pre">TensorWrapper</span></code> Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="expression.html">Designing the Expression Component</a></li>
<li class="toctree-l3"><a class="reference internal" href="op_graph.html">Designing the OpGraph</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse_maps/index.html">Sparse Maps Sublibrary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bibliography/bibliography.html">References</a></li>
<li class="toctree-l1"><a class="reference external" href="https://nwchemex-project.github.io/TensorWrapper/tensorwrapper_cxx_api/index.html">C++ API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">TensorWrapper</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Developer Documentation</a></li>
          <li class="breadcrumb-item"><a href="index.html">Design of TensorWrapper</a></li>
      <li class="breadcrumb-item active">Designing the Buffer</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/NWChemEx-Project/TensorWrapper/edit/master/docs/source/developer/design/buffer.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="designing-the-buffer">
<span id="tw-designing-the-buffer"></span><h1>Designing the Buffer<a class="headerlink" href="#designing-the-buffer" title="Permalink to this heading"></a></h1>
<p>The point of this page is to record the design process of TensorWrapper’s
buffer component.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Based on <code class="docutils literal notranslate"><span class="pre">TensorWrapper</span></code> design, this needs reworked. Namely <code class="docutils literal notranslate"><span class="pre">Buffer</span></code>
should be a single class, with a polymorphic PIMPL. In particular, users
may need to give up ownership of <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> objects which is easier to do
if <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> is not polymorphic.</p>
</div>
<div class="section" id="what-is-the-buffer">
<h2>What is the Buffer?<a class="headerlink" href="#what-is-the-buffer" title="Permalink to this heading"></a></h2>
<p>To vastly over simplify, tensors consist of two things: the literal elements of
the tensor and all the additional properties and mathematical structure imposed
on top of those elements. The <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> class is responsible for holding the
literal elements of the tensor and being able to describe physically how those
elements are held.</p>
</div>
<div class="section" id="why-do-we-need-a-buffer">
<h2>Why do we need a Buffer?<a class="headerlink" href="#why-do-we-need-a-buffer" title="Permalink to this heading"></a></h2>
<p>TensorWrapper is ultimately powered by other tensor libraries. The boundary
between those libraries and TensorWrapper is the <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> class. The
<code class="docutils literal notranslate"><span class="pre">Buffer</span></code> class is the interface through which the user’s intentions (specified
with the TensorWrapper <a class="reference internal" href="../../background/terminology.html#term-dsl"><span class="std std-ref">domain specific language (DSL)</span></a>) are conveyed to the backend.</p>
</div>
<div class="section" id="buffer-terminology">
<h2>Buffer Terminology<a class="headerlink" href="#buffer-terminology" title="Permalink to this heading"></a></h2>
<dl class="simple">
<dt>distributed</dt><dd><p>A buffer is distributed if it has both local and remote pieces. By contrast
remote buffers only contain remote data (no local data).</p>
</dd>
<dt>future (to a buffer)</dt><dd><p>A future to a buffer is an object which will eventually be a buffer, but at
the time of creation may not actually have its data yet. Futures to buffers
typically arise when a task scheduler is creating buffers and we do not want
to wait for the scheduler to create the buffer. In this case a backgrounded
task for creating the buffer is added to the scheduler and control
continues with only a future to the result. Once the backgrounded task
has completed creating the buffer, the buffer can be accessed directly
from the future to the buffer. If control requests the buffer before it has
been created, then control must wait until the buffer is ready before
continuing.</p>
</dd>
<dt>on demand</dt><dd><p>An “on demand” buffer does not store the values which live in it, but
instead creates them when requested. This differs from a future in that the
values of an on-demand tensor are “immediately available” (not accounting for
the delay required to compute them).</p>
</dd>
<dt>local</dt><dd><p>A buffer is “local” if the current process can access the state of the
buffer without communicating with another process. A local buffer is the
opposite of a remote buffer</p>
</dd>
<dt>remote</dt><dd><p>A buffer is “remote” if none of the state can be accessed without
communicating with another process. A remote buffer has no local piece (if it
has a local piece it is a distributed buffer).</p>
</dd>
</dl>
</div>
<div class="section" id="buffer-considerations">
<h2>Buffer Considerations<a class="headerlink" href="#buffer-considerations" title="Permalink to this heading"></a></h2>
<dl class="simple" id="b-wrapping-other-tensor-libraries">
<dt>Wrapping other tensor libraries.</dt><dd><p>In practice the literal data layouts of a tensor can be very complicated.
Many existing tensor libraries have already optimized tensor operations on
their data structures for some particular scenarios. We do not want to
reinvent those optimizations and suggest <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> should actually wrap
those libraries’ data structures.</p>
<ul class="simple">
<li><p>We note that creating those structures is the responsibility of the
<code class="docutils literal notranslate"><span class="pre">Allocator</span></code> component (see <a class="reference internal" href="allocator.html#tw-designing-the-allocator"><span class="std std-ref">Designing the Allocator</span></a>).</p></li>
</ul>
</dd>
</dl>
<dl class="simple" id="b-type-erasure">
<dt>Type erasure</dt><dd><p>As consideration <a class="reference internal" href="#b-wrapping-other-tensor-libraries"><span class="std std-ref">Wrapping other tensor libraries.</span></a> states, the
<code class="docutils literal notranslate"><span class="pre">Buffer</span></code> objects do not just hold <code class="docutils literal notranslate"><span class="pre">double*</span></code>, but rather tensor-like
objects from existing tensor libraries. To allow the various tensor libraries
to be somewhat interoperable we propose that the <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> objects type-
erase the backend they hold.</p>
<ul class="simple">
<li><p>We will need to be able to unwrap the type-erased object too.</p></li>
<li><p>The set of methods exposed by the <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> class needs to be very
general so as to have analogs in every possible backend.</p></li>
</ul>
</dd>
</dl>
<dl class="simple" id="b-data-location">
<dt>Data location</dt><dd><p>How a user interacts with a <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> depends on where the data lives.
Data that can only be seen by the current process is usually treated
differently than data which all processes can see.</p>
<ul class="simple">
<li><p>Need to know if data is distributed, local, or replicated.</p></li>
<li><p>For distributed data, need to be able to replicate, get handles to remote
data, and access local data.</p></li>
</ul>
</dd>
</dl>
<dl class="simple" id="b-on-demand-data">
<dt>On demand data</dt><dd><p>Particularly for high-rank tensors, we often do not store data explicitly.
The <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> must be able to work seamlessly when data is computed
on demand.</p>
<ul class="simple">
<li><p>In practice, tensors which are computed on demand still usually store some
state.</p></li>
</ul>
</dd>
</dl>
<dl class="simple" id="b-asynchronous-support">
<dt>Asynchronous support</dt><dd><p>We want the creation of a distributed tensor to be asynchronous. For this
to work, we need the ability to have proxy <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> objects. Such objects
will eventually be filled in, but in the meantime control can continue to
use them to build up an operation queue. Attempting to access such a
<code class="docutils literal notranslate"><span class="pre">Buffer</span></code> results in waiting until the <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> has been filled in.</p>
</dd>
</dl>
<dl class="simple" id="b-basic-operations">
<dt>Basic operations</dt><dd><p>Collectively, the various tensor backends expose many possible operations.
The operations exposed by the <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> classes should be very basic
operations which should be present in each backend.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Buffer</span></code> objects should contain their layouts, users should be able to
inspect those layouts.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> should have access to the runtime it belongs to.</p></li>
<li><p>Slices and chips for moving data around.</p></li>
<li><p>Actually executing an <code class="docutils literal notranslate"><span class="pre">OpGraph</span></code> accounts for any additional operations
the backend needs to run.</p></li>
</ul>
</dd>
</dl>
<div class="section" id="out-of-scope">
<h3>Out of Scope<a class="headerlink" href="#out-of-scope" title="Permalink to this heading"></a></h3>
<dl class="simple">
<dt>Tensor math</dt><dd><p>While mathematical operations on tensors are arguably fundamental, the
reality is each backend is going to approach those operations in a different
manner. Attempting to unify these operations would be difficult. In our
opinion a better solution is to queue up a set of operations to be done and
then tell the backend to do them.</p>
<ul class="simple">
<li><p>Evaluating a set of operations is in scope and is covered by
<a class="reference internal" href="#b-basic-operations"><span class="std std-ref">Basic operations</span></a></p></li>
</ul>
</dd>
<dt>Backend Allocation</dt><dd><p>Literally making an object of the backend is a fundamental tensor operation;
however, like “Tensor math” above, the creation of a backend object is
going to be heavily dependent on the identity of the backend.</p>
<ul class="simple">
<li><p>The responsibility for allocating <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> objects is punted to the
<code class="docutils literal notranslate"><span class="pre">Allocator</span></code> component. See <a class="reference internal" href="allocator.html#tw-designing-the-allocator"><span class="std std-ref">Designing the Allocator</span></a> for
more details.</p></li>
</ul>
</dd>
</dl>
</div>
</div>
<div class="section" id="buffer-design">
<h2>Buffer Design<a class="headerlink" href="#buffer-design" title="Permalink to this heading"></a></h2>
<div class="figure align-center" id="id1">
<span id="fig-buffer"></span><img alt="../../_images/buffer.png" src="../../_images/buffer.png" />
<p class="caption"><span class="caption-number">Fig. 10 </span><span class="caption-text">Design of the buffer component of TensorWrapper.</span><a class="headerlink" href="#id1" title="Permalink to this image"></a></p>
</div>
<p><a class="reference internal" href="#fig-buffer"><span class="std std-numref">Fig. 10</span></a> shows the major components of TensorWrapper’s buffer
component. In addressing the <a class="reference internal" href="#b-wrapping-other-tensor-libraries"><span class="std std-ref">Wrapping other tensor libraries.</span></a>
consideration we made the decision to have each tensor library derive one or
more buffer types. The backend-specific classes are responsible for implementing
the interfaces of the classes they derive from. Additionally, the backend-
specific classes will allow users to retrieve the native data structure if need
be. The classes that the backend-specific classes derive from do not contain
reference to the various backends, in particular TensorWrapper will pass most
buffer objects around by pointers to the <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> base class, thus
satisfying the <a class="reference internal" href="#b-type-erasure"><span class="std std-ref">Type erasure</span></a> consideration.</p>
<p>For writing generic algorithms we usually need more information. Deriving from
<code class="docutils literal notranslate"><span class="pre">Buffer</span></code> we have several classes including: <code class="docutils literal notranslate"><span class="pre">LocalBuffer</span></code>,
<code class="docutils literal notranslate"><span class="pre">OnDemandBuffer</span></code>, <code class="docutils literal notranslate"><span class="pre">ReplicatedBuffer</span></code>, <code class="docutils literal notranslate"><span class="pre">FutureBuffer</span></code>, and
<code class="docutils literal notranslate"><span class="pre">DistributedBuffer</span></code>. Together these classes address <a class="reference internal" href="#b-data-location"><span class="std std-ref">Data location</span></a>,
<a class="reference internal" href="#b-on-demand-data"><span class="std std-ref">On demand data</span></a>, and <a class="reference internal" href="#b-asynchronous-support"><span class="std std-ref">Asynchronous support</span></a>.</p>
</div>
<div class="section" id="proposed-apis">
<h2>Proposed APIs<a class="headerlink" href="#proposed-apis" title="Permalink to this heading"></a></h2>
<div class="section" id="creating-a-buffer">
<h3>Creating a Buffer<a class="headerlink" href="#creating-a-buffer" title="Permalink to this heading"></a></h3>
<p>Creating a <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> is done through an allocator. For now we treat allocators
as largely opaque objects (design details for the allocator component can be
found in the <a class="reference internal" href="allocator.html#tw-designing-the-allocator"><span class="std std-ref">Designing the Allocator</span></a> section). Using an allocator,
the typical process for creating a buffer looks like:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">alloc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_allocator</span><span class="p">();</span><span class="w"> </span><span class="c1">//N.B. allocators know about the runtime</span>
<span class="n">Layout</span><span class="w"> </span><span class="n">l</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">get_layout</span><span class="p">();</span><span class="w"> </span><span class="c1">// Figure out the tensor&#39;s shape, symmetry, etc.</span>

<span class="c1">// This constructs a 0-initialized buffer. Other constructions are possible</span>
<span class="k">auto</span><span class="w"> </span><span class="n">pbuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">alloc</span><span class="p">.</span><span class="n">construct</span><span class="p">(</span><span class="n">l</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">);</span>
</pre></div>
</div>
<p>Since buffers are polymorphic objects, allocators return smart pointers to base
classes of the actual object (the exact base class returned depends on the
allocator).</p>
</div>
<div class="section" id="retrieving-the-wrapped-tensor">
<h3>Retrieving the Wrapped Tensor<a class="headerlink" href="#retrieving-the-wrapped-tensor" title="Permalink to this heading"></a></h3>
<p>Until TensorWrapper is fleshed out we anticipate that users will need to
unwrap the buffer somewhat regularly. We propose that this is done by:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Get a pointer to a buffer object we want to unwrap</span>
<span class="k">auto</span><span class="w"> </span><span class="n">pbuffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_buffer</span><span class="p">();</span>

<span class="c1">// Declare the allocator for the appropriate backend, here we use the TADist</span>
<span class="c1">// allocator</span>
<span class="n">TADist</span><span class="w"> </span><span class="nf">alloc</span><span class="p">(</span><span class="n">pbuffer</span><span class="o">-&gt;</span><span class="n">runtime</span><span class="p">());</span>

<span class="c1">// This call will create a DistributedBuffer with TA as the backend by</span>
<span class="c1">// copying *pbuffer. Moving *pbuffer would (potentially) avoid the copy</span>
<span class="k">auto</span><span class="w"> </span><span class="n">converted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">alloc</span><span class="p">.</span><span class="n">construct</span><span class="p">(</span><span class="o">*</span><span class="n">pbuffer</span><span class="p">);</span>
</pre></div>
</div>
<p>Generally speaking, conversions work best if the layout of the input buffer is
also supported by the output buffer. If the layouts are not compatible it is
left up to the allocator how to deal with this.</p>
</div>
<div class="section" id="working-with-distributed-buffers">
<h3>Working with Distributed Buffers<a class="headerlink" href="#working-with-distributed-buffers" title="Permalink to this heading"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">DistributedBuffer</span></code> extends the <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> class to the scenario when the
underlying <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> object has data potentially distributed across multiple
processes.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">dist_buffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_buffer</span><span class="p">();</span>

<span class="c1">// Gets a handle to the part of the distributed buffer which is local to</span>
<span class="c1">// the current process</span>
<span class="n">LocalBuffer</span><span class="w"> </span><span class="n">my_buffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dist_buffer</span><span class="p">.</span><span class="n">local_buffer</span><span class="p">();</span>

<span class="c1">// Gets a handle to a part of the distributed buffer whose state is not</span>
<span class="c1">// local to the current process. N.B. this does NOT make the data local</span>
<span class="c1">// yet. We do assume that every process knows how to do this with no</span>
<span class="c1">// communication though (chips work too)</span>
<span class="k">auto</span><span class="w"> </span><span class="n">shape_of_slice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_shape_of_the_slice</span><span class="p">();</span>
<span class="n">RemoteBuffer</span><span class="w"> </span><span class="n">a_buffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dist_buffer</span><span class="p">.</span><span class="n">slice</span><span class="p">(</span><span class="n">shape_of_slice</span><span class="p">);</span>

<span class="c1">// Actually pulls the data</span>
<span class="k">auto</span><span class="w"> </span><span class="n">now_its_local</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a_buffer</span><span class="p">.</span><span class="n">local_buffer</span><span class="p">();</span>

<span class="c1">// To make the distributed buffer replicated</span>
<span class="k">auto</span><span class="w"> </span><span class="n">rep_alloc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dist_buffer</span><span class="p">.</span><span class="n">allocator</span><span class="p">().</span><span class="n">rebind</span><span class="o">&lt;</span><span class="n">ReplicatedBuffer</span><span class="o">&gt;</span><span class="p">();</span>
<span class="k">auto</span><span class="w"> </span><span class="n">preplicated</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rep_alloc</span><span class="p">.</span><span class="n">construct</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">dist_buffer</span><span class="p">));</span>
</pre></div>
</div>
<p>We note that <code class="docutils literal notranslate"><span class="pre">DistributedBuffer</span></code> objects will have <code class="docutils literal notranslate"><span class="pre">Nested</span></code> shapes. The
outer layer of the shape will describe the block boundaries so that users can
avoid choosing slices/chips that cross said boundaries.</p>
</div>
<div class="section" id="other-buffer-methods">
<h3>Other Buffer Methods<a class="headerlink" href="#other-buffer-methods" title="Permalink to this heading"></a></h3>
<p>Once you have a <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> basic operations include:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">buffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_buffer</span><span class="p">();</span>

<span class="c1">// Get the shape, symmetry, or sparsity of the buffer</span>
<span class="k">auto</span><span class="w"> </span><span class="n">shape</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="n">buffer</span><span class="p">.</span><span class="n">shape</span><span class="p">();</span>
<span class="k">auto</span><span class="w"> </span><span class="n">symmetry</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">buffer</span><span class="p">.</span><span class="n">symmetry</span><span class="p">();</span>
<span class="k">auto</span><span class="w"> </span><span class="n">sparsity</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">buffer</span><span class="p">.</span><span class="n">sparsity</span><span class="p">();</span>

<span class="c1">// Request slices and chips</span>
<span class="k">auto</span><span class="w"> </span><span class="n">a_slice</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">buffer</span><span class="p">.</span><span class="n">slice</span><span class="p">(</span><span class="n">shape</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">a_chip</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">buffer</span><span class="p">.</span><span class="n">chip</span><span class="p">(</span><span class="n">shape</span><span class="p">);</span>
</pre></div>
</div>
<p>The expression layer (see <a class="reference internal" href="expression.html#designing-the-expression-component"><span class="std std-ref">Designing the Expression Component</span></a>) results in
a <a class="reference internal" href="../../background/terminology.html#term-cst"><span class="std std-ref">concrete syntax tree (CST)</span></a>. TensorWrapper will convert the CST into an <a class="reference internal" href="../../background/terminology.html#term-ast"><span class="std std-ref">abstract syntax tree (AST)</span></a>,
which is then passed to the backend via:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Somehow get the buffer the result will be assigned to</span>
<span class="k">auto</span><span class="w"> </span><span class="n">buffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_buffer</span><span class="p">();</span>

<span class="c1">// Get the AST, which is an OpGraph object</span>
<span class="k">auto</span><span class="w"> </span><span class="n">graph</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_op_graph</span><span class="p">();</span>

<span class="c1">// Use the AST to update the buffer&#39;s state accordingly</span>
<span class="n">buffer</span><span class="p">.</span><span class="n">compute</span><span class="p">(</span><span class="n">graph</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this heading"></a></h2>
<dl class="simple">
<dt><a class="reference internal" href="#b-wrapping-other-tensor-libraries"><span class="std std-ref">Wrapping other tensor libraries.</span></a></dt><dd><p>For each tensor backend we define one or more buffers. Each buffer derives
from the TensorWrapper buffer type which best summarizes the storage
strategy of the backend.</p>
</dd>
<dt><a class="reference internal" href="#b-type-erasure"><span class="std std-ref">Type erasure</span></a></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> class is a common base class for all components of the
<code class="docutils literal notranslate"><span class="pre">Buffer</span></code> component. Passing objects via the <code class="docutils literal notranslate"><span class="pre">Buffer</span></code> base class
type-erases the backend.</p>
</dd>
<dt><a class="reference internal" href="#b-data-location"><span class="std std-ref">Data location</span></a></dt><dd><p>In the design of the buffer component, we derive several classes
including: <code class="docutils literal notranslate"><span class="pre">LocalBuffer</span></code>, <code class="docutils literal notranslate"><span class="pre">OnDemandBuffer</span></code>, and <code class="docutils literal notranslate"><span class="pre">DistributedBuffer</span></code>,
which represent the storage strategy of the backend. Additional classes can
be added as needed to, for example, distinguish between buffers living in
RAM versus on the GPU.</p>
</dd>
<dt><a class="reference internal" href="#b-on-demand-data"><span class="std std-ref">On demand data</span></a></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">OnDemandBuffer</span></code> class has been introduced to cover this consideration.</p>
</dd>
<dt><a class="reference internal" href="#b-asynchronous-support"><span class="std std-ref">Asynchronous support</span></a></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">FutureBuffer</span></code> class template has been introduced to cover this
consideration.</p>
</dd>
<dt><a class="reference internal" href="#b-basic-operations"><span class="std std-ref">Basic operations</span></a></dt><dd><p>The example APIs given demonstrate how basic operations may be performed.</p>
</dd>
</dl>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="allocator.html" class="btn btn-neutral float-left" title="Designing the Allocator" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="tensor_wrapper.html" class="btn btn-neutral float-right" title="Designing TensorWrapper Class" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, NWChemEx Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>