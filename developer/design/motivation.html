<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Motivating TensorWrapper &mdash; TensorWrapper 1.0.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Overview of TensorWrapper" href="overview.html" />
    <link rel="prev" title="Design of TensorWrapper" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/logo_candybar.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.0.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../background/index.html">TensorWrapper Background</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Developer Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Design of TensorWrapper</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Motivating TensorWrapper</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#why-tensors">Why Tensors?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#are-tensors-a-sufficient-dsl">Are tensors a sufficient DSL?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#why-tensorwrapper">Why TensorWrapper?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="overview.html">Overview of TensorWrapper</a></li>
<li class="toctree-l3"><a class="reference internal" href="shape.html">Tensor Shape Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="symmetry.html">Designing the Symmetry Component</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparsity.html">Tensor Sparsity Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="layout.html">Designing the Layout Component</a></li>
<li class="toctree-l3"><a class="reference internal" href="allocator.html">Designing the Allocator</a></li>
<li class="toctree-l3"><a class="reference internal" href="buffer.html">Designing the Buffer</a></li>
<li class="toctree-l3"><a class="reference internal" href="tensor_wrapper.html">Designing <code class="docutils literal notranslate"><span class="pre">TensorWrapper</span></code> Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="expression.html">Designing the Expression Component</a></li>
<li class="toctree-l3"><a class="reference internal" href="op_graph.html">Designing the OpGraph</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparse_maps.html">Designing the Sparse Map Component</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse_maps/index.html">Sparse Maps Sublibrary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bibliography/bibliography.html">References</a></li>
<li class="toctree-l1"><a class="reference external" href="https://nwchemex-project.github.io/TensorWrapper/tensorwrapper_cxx_api/index.html">C++ API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">TensorWrapper</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Developer Documentation</a></li>
          <li class="breadcrumb-item"><a href="index.html">Design of TensorWrapper</a></li>
      <li class="breadcrumb-item active">Motivating TensorWrapper</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/NWChemEx-Project/TensorWrapper/edit/master/docs/source/developer/design/motivation.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="motivating-tensorwrapper">
<h1>Motivating TensorWrapper<a class="headerlink" href="#motivating-tensorwrapper" title="Permalink to this headline"></a></h1>
<section id="why-tensors">
<h2>Why Tensors?<a class="headerlink" href="#why-tensors" title="Permalink to this headline"></a></h2>
<p>TensorWrapper defines a tensor as a multi-dimensional array of values. The
values are usually scalars, but in general can be other tensors. In practice
this means that more-or-less any indexed quantity is a tensor (according to
TensorWrapper). Given the prevalence of indexed-quantities in physics
equations, tensors can be seen as a natural domain-specific language (DSL)
for physics, since most physics theories can be expressed succinctly in terms
of tensors. As a perfect example consider the energy, <span class="math notranslate nohighlight">\(E\)</span>, of an
<span class="math notranslate nohighlight">\(N\)</span>-dimensional harmonic oscillator:</p>
<div class="math notranslate nohighlight">
\[E = \frac{1}{2}\sum_{i=1}^N k_i \left(r_i - r^{(0)}_i\right)^2\]</div>
<p>where <span class="math notranslate nohighlight">\(k_i\)</span> and <span class="math notranslate nohighlight">\(\left(r_i-r^{(0)}_i\right)\)</span> respectively are the
force constant and displacement in the <span class="math notranslate nohighlight">\(i\)</span>-th dimension. This is a perfect
example because the equation is simple to express in terms of tensors, but
few people would actually code this up as a tensor equation, which brings us
to…</p>
</section>
<section id="are-tensors-a-sufficient-dsl">
<h2>Are tensors a sufficient DSL?<a class="headerlink" href="#are-tensors-a-sufficient-dsl" title="Permalink to this headline"></a></h2>
<p>In practice, most people would compute <span class="math notranslate nohighlight">\(E\)</span> something like:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="kt">double</span><span class="w"> </span><span class="n">e</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span><span class="p">;</span><span class="w"></span>
<span class="k">for</span><span class="p">(</span><span class="k">auto</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">N</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">){</span><span class="w"></span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">dr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">r</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">r0</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="w"></span>
<span class="w">    </span><span class="n">e</span><span class="o">+=</span><span class="w"> </span><span class="n">k</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dr</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dr</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
<span class="k">return</span><span class="w"> </span><span class="mf">0.5</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">e</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
<p>That is they’d use a for-loop. Why? Consider pseudo code for the tensor-based
version:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">Tensor</span><span class="w"> </span><span class="n">dr</span><span class="p">,</span><span class="w"> </span><span class="n">dr2</span><span class="p">,</span><span class="w"> </span><span class="n">e</span><span class="p">;</span><span class="w"></span>
<span class="n">dr</span><span class="p">(</span><span class="s">&quot;i&quot;</span><span class="p">)</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">r</span><span class="p">(</span><span class="s">&quot;i&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">r0</span><span class="p">(</span><span class="s">&quot;i&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">dr2</span><span class="p">(</span><span class="s">&quot;i&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dr</span><span class="p">(</span><span class="s">&quot;i&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dr</span><span class="p">(</span><span class="s">&quot;i&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">e</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">k</span><span class="p">(</span><span class="s">&quot;i&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">dr2</span><span class="p">(</span><span class="s">&quot;i&quot;</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>Ignoring compiler optimizations, and taking the code at face value the
operation counts are the same for each algorithm (<span class="math notranslate nohighlight">\(N\)</span>
subtractions, <span class="math notranslate nohighlight">\(N\)</span> squares, and an <span class="math notranslate nohighlight">\(N\)</span>-element dot-product). The primary
difference is that the tensor version stores two additional <span class="math notranslate nohighlight">\(N\)</span>-element vectors
(the displacements and the square of the displacements). While not strictly
inferrable from the code presented here, assuming <code class="docutils literal notranslate"><span class="pre">r</span></code>,
<code class="docutils literal notranslate"><span class="pre">r0</span></code>, and <code class="docutils literal notranslate"><span class="pre">k</span></code> are something akin to a <code class="docutils literal notranslate"><span class="pre">double</span> <span class="pre">*</span></code>, it is also quite
likely that the compiler will be able to better optimize the loop-based
version.</p>
<p>So if the for-loop produces better overall code, why would we want the DSL
version? The short answer is the for-loop based version is not optimal in
all situations. By using the DSL, we can express our intent while punting the
optimizations to the backend. This is because, using modern object-oriented
programming techniques, there is a disconnect between the apparent API and how
things are actually implemented. Point being, just because the tensor DSL code
looks like it has extra memory usage doesn’t mean it really does (simple
reference counting techniques could identify <code class="docutils literal notranslate"><span class="pre">dr</span></code> and <code class="docutils literal notranslate"><span class="pre">dr2</span></code> as
intermediates). Furthermore it’s entirely possible that, as written, the
implementation underlying the tensor DSL is parallelized and/or GPU
accelerated. The loop-based version is, however, not parallelized, and would
need to be rewritten for threading and or process parallelization. This can
potentially be a lot of work if multiple loop-based implementations need to be
rewritten.</p>
</section>
<section id="why-tensorwrapper">
<h2>Why TensorWrapper?<a class="headerlink" href="#why-tensorwrapper" title="Permalink to this headline"></a></h2>
<p>In short, there’s no tensor library out there (that we can find) that really
strives to achieve the full-featured DSL we want. While a number of tensor
libraries have a DSL, the libraries assume you’re willing to drop out of the
DSL for more complicated optimizations. In practice, these are precisely the
optimizations we are interested in.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Design of TensorWrapper" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="overview.html" class="btn btn-neutral float-right" title="Overview of TensorWrapper" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, NWChemEx Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>