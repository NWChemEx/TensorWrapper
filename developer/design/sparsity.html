<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tensor Sparsity Design &mdash; TensorWrapper 1.0.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Designing the Layout Component" href="layout.html" />
    <link rel="prev" title="Designing the Symmetry Component" href="symmetry.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/logo_candybar.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.0.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../background/index.html">TensorWrapper Background</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Developer Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Design of TensorWrapper</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="motivation.html">Motivating TensorWrapper</a></li>
<li class="toctree-l3"><a class="reference internal" href="overview.html">Overview of TensorWrapper</a></li>
<li class="toctree-l3"><a class="reference internal" href="shape.html">Tensor Shape Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="symmetry.html">Designing the Symmetry Component</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Tensor Sparsity Design</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#what-is-tensor-sparsity">What is tensor sparsity?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#why-do-we-need-tensor-sparsity">Why do we need tensor sparsity?</a></li>
<li class="toctree-l4"><a class="reference internal" href="#sparsity-considerations">Sparsity considerations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1">Sparsity Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="#proposed-apis">Proposed APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="layout.html">Designing the Layout Component</a></li>
<li class="toctree-l3"><a class="reference internal" href="allocator.html">Designing the Allocator</a></li>
<li class="toctree-l3"><a class="reference internal" href="buffer.html">Designing the Buffer</a></li>
<li class="toctree-l3"><a class="reference internal" href="tensor_wrapper.html">Designing <code class="docutils literal notranslate"><span class="pre">TensorWrapper</span></code> Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="expression.html">Designing the Expression Component</a></li>
<li class="toctree-l3"><a class="reference internal" href="op_graph.html">Designing the OpGraph</a></li>
<li class="toctree-l3"><a class="reference internal" href="sparse_maps.html">Designing the Sparse Map Component</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse_maps/index.html">Sparse Maps Sublibrary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bibliography/bibliography.html">References</a></li>
<li class="toctree-l1"><a class="reference external" href="https://nwchemex-project.github.io/TensorWrapper/tensorwrapper_cxx_api/index.html">C++ API</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">TensorWrapper</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Developer Documentation</a></li>
          <li class="breadcrumb-item"><a href="index.html">Design of TensorWrapper</a></li>
      <li class="breadcrumb-item active">Tensor Sparsity Design</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/NWChemEx-Project/TensorWrapper/edit/master/docs/source/developer/design/sparsity.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="tensor-sparsity-design">
<span id="sparsity-design"></span><h1>Tensor Sparsity Design<a class="headerlink" href="#tensor-sparsity-design" title="Permalink to this headline"></a></h1>
<p>This page documents the process of designing the sparsity component of
TensorWrapper.</p>
<section id="what-is-tensor-sparsity">
<h2>What is tensor sparsity?<a class="headerlink" href="#what-is-tensor-sparsity" title="Permalink to this headline"></a></h2>
<p>In the context of tensors, sparsity refers to tensors possessing elements which
are effectively zero. Exactly what defines the effective zero is situational
and problem-specific. The sparsity component is responsible for indicating
which elements are zero or non-zero, not only in a single tensor, but also in
tensor expressions.</p>
</section>
<section id="why-do-we-need-tensor-sparsity">
<h2>Why do we need tensor sparsity?<a class="headerlink" href="#why-do-we-need-tensor-sparsity" title="Permalink to this headline"></a></h2>
<p>If a tensor exhibits a substantial amount of sparsity, then implicitly storing
the zero values leads to a significant space savings. Furthermore, because of
the special properties of zero, <em>e.g.</em>, <span class="math notranslate nohighlight">\(\mathbf{T}+\mathbf{0}=\mathbf{T}\)</span>
and <span class="math notranslate nohighlight">\(\mathbf{T}\mathbf{0}=\mathbf{0}\)</span>, many tensor operations involving
sparse tensors can be done implicitly.</p>
</section>
<section id="sparsity-considerations">
<h2>Sparsity considerations<a class="headerlink" href="#sparsity-considerations" title="Permalink to this headline"></a></h2>
<dl class="simple" id="sparse-element-sparsity">
<dt>Element Sparsity</dt><dd><p>Element sparsity is concerned with specifying whether each individual
element of a tensor is zero/non-zero. An element sparse tensor has isolated
non-zero elements, each surrounded by a “sea” of zero elements.</p>
<ul class="simple">
<li><p>Effectively exploiting element sparsity requires custom linear algebra
routines designed to act element-wise, rather than on contiguous blocks.</p></li>
<li><p>In theory, TensorWrapper could look at a provided element sparsity,
back out a block-sparsity (vide infra), and use whichever sparsity leads
to better performance, but for now TensorWrapper assumes the user has
already done such an analysis.</p></li>
</ul>
</dd>
</dl>
<dl class="simple" id="sparse-block-sparsity">
<dt>Block Sparsity</dt><dd><p>Block sparsity is concerned with specifying whether multi-element
<a class="reference internal" href="../../background/terminology.html#term-slice"><span class="std std-ref">slice</span></a> and <a class="reference internal" href="../../background/terminology.html#term-chip"><span class="std std-ref">chip</span></a> of a tensor are all zero of if they
contain non-zero elements. It should be noted that a slice/chip is zero only
if every element in the chip is zero too. Since slices/chips can contain a
single element the distinction between element and block sparsity is not
always clear. Simply put, element vs block sparsity comes down to
whether the user provided the sparsity component with single elements or
chips/slices.</p>
<ul class="simple">
<li><p>Exploiting block-wise sparsity can only be done with block-wise operations
(either involving chips or slices).</p></li>
<li><p>Block-wise operations are either done manually by interacting with
slices/chips of a tensor, or automatically when an operation involves a
nested tensor.</p></li>
<li><p>As a result of the previous point, tensors declared with either a
<code class="docutils literal notranslate"><span class="pre">JaggedShape</span></code> or a <code class="docutils literal notranslate"><span class="pre">Nested</span></code> shape benefit most from block sparsity.
Here it should be noted that the former has an implicit
nesting resulting from the boundary between the jagged and smooth ranks,
whereas the latter has explicit nestings.</p></li>
</ul>
</dd>
</dl>
<dl class="simple" id="sparse-effective-sparsity">
<dt>Effective Sparsity</dt><dd><p>In practice we are not only concerned with hard zeros (elements, slices, or
chips which are identically zero), but also values which are so small that
for all intents and purposes they are zero. The sparsity component needs to
exploit this effective sparsity as well.</p>
</dd>
</dl>
<dl class="simple" id="sparse-operational-sparsity">
<dt>Operational Sparsity</dt><dd><p>Given an operation combining two tensors, <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{B}\)</span>, to form <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> we
need to be able to work out the sparsity of <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> from the sparsity of <span class="math notranslate nohighlight">\(\mathbf{A}\)</span>
and <span class="math notranslate nohighlight">\(\mathbf{B}\)</span>.</p>
<ul class="simple">
<li><p>To work out the sparsity of <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> we need the shapes of <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{B}\)</span>. Having
the symmetry makes it potentially more efficient.</p></li>
</ul>
</dd>
</dl>
<dl class="simple" id="sparse-effective-operational-sparsity">
<dt>Effective Operational Sparsity</dt><dd><p>Given two tensors, <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{B}\)</span>, which are not sparse, it is possible to
combine <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> to form <span class="math notranslate nohighlight">\(\mathbf{C}\)</span>, and have <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> be sparse. Of particular note,
is when <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> contain values with magnitudes between 0 and 1, in which
case the elements of <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> will have even smaller magnitudes than those in
either <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> or <span class="math notranslate nohighlight">\(\mathbf{B}\)</span>.</p>
<ul class="simple">
<li><p>Another important case is subtraction; if <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> are approximately
equal then their difference will be approximately zero. This is
particularly important for iterative methods where converged elements do
not change among iterations.</p></li>
<li><p>Sparsity may arise through addition, if <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> have opposite signs.
In this case the resulting sparsity is similar to that which results from
subtraction.</p></li>
<li><p>Exploiting effective operational sparsity requires use of inequalities
such as Cacuchy-Schwarz. For elemental sparsity these inequalities must be
considered element by element and offer no cost savings over simply
carrying out the operation and inspecting the result (n.b., that inspecting
the result, <span class="math notranslate nohighlight">\(\mathbf{C}\)</span>,  for additional sparsity can be useful if <span class="math notranslate nohighlight">\(\mathbf{C}\)</span> is used
later). For block sparsity, inequalities can be checked by using block
norms. If the norms fail the inequality then it is possible to avoid
forming the full sparse block.</p></li>
</ul>
</dd>
</dl>
<dl class="simple" id="sparse-dual-problem">
<dt>Dual problem</dt><dd><p>Since a sparse tensor has a lot of zeros, sparsity specification is usually
thought of in terms of specifying the non-zero elements. Since a given
tensor element is either zero or non-zero, we can just as easily think of
sparsity specification via the dual problem, <em>i.e.</em>, specifying the zero
elements of a tensor. Users will in general prefer to to specify the sparsity
which ever way is quicker.</p>
<ul class="simple">
<li><p>Even if a tensor is predominantly dense, exploiting sparsity, particularly
block sparsity, can still lead to major performance improvements.</p></li>
<li><p>In order to be able to switch between representations we need to know the
overall shape of the tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="simple" id="sparse-symmetry">
<dt>Symmetry</dt><dd><p>Knowing the symmetry of the tensor allows us to know where zero/non-zero
elements are with less information.</p>
</dd>
</dl>
<dl class="simple" id="sparse-basic-operations">
<dt>Basic Operations</dt><dd><p>In addition to constructing a representation of a tensor’s sparsity we also
need to know:</p>
<ul class="simple">
<li><p>Whether an element/range of elements is zero or not.</p></li>
<li><p>The fraction of zero elements (<em>i.e.</em>, the sparsity).</p></li>
<li><p>Unions of sparsity objects (for algorithm purposes and useful for building
up the final sparsity).</p></li>
</ul>
</dd>
</dl>
<section id="not-in-scope">
<h3>Not in Scope<a class="headerlink" href="#not-in-scope" title="Permalink to this headline"></a></h3>
<dl class="simple">
<dt>Storage format</dt><dd><p>A number of schemes exist for storing sparse tensors, <em>e.g.</em>, compressed
sparse row and compressed sparse column. While the sparsity component will
need to adopt one (or possibly multiple) formats, doing so is an
implementation detail and not explicitly considered in the user-facing
design.</p>
</dd>
<dt>Sparse Map</dt><dd><p>For a matrix, compressed sparse row format is a map from non-zero row
indices to non-zero column indices. For example, if for a 3 by 3 matrix,
row 0 has two non-zero elements, in columns 1 and 2, row 1 is only non-zero
at column 0, and row 2 is zero. We can express this with the map
<code class="docutils literal notranslate"><span class="pre">{0</span> <span class="pre">:</span> <span class="pre">{1,</span> <span class="pre">2},</span> <span class="pre">1</span> <span class="pre">:</span> <span class="pre">{0}}</span></code>. For higher rank tensors, it is possible to compose
these maps. For example, say that we want to map the rows in our original
matrix to products of the columns, we then know that we only need to consider
the components <code class="docutils literal notranslate"><span class="pre">{0</span> <span class="pre">:</span> <span class="pre">{{1,</span> <span class="pre">1},</span> <span class="pre">{1,</span> <span class="pre">2},</span> <span class="pre">{2,</span> <span class="pre">1},</span> <span class="pre">{2,2}},</span> <span class="pre">1</span> <span class="pre">:</span> <span class="pre">{0.0}}</span></code>.</p>
<ul class="simple">
<li><p>The real power of sparse maps comes in when you compose them over a series
of expressions. In particular, given an expression and a series of sparse
map objects, sparse maps can be used to create the element/block sparsity
of the expression.</p></li>
<li><p>As such, sparse maps are a mechanism for creating objects which live in the
sparsity component and are not considered further here. Sparse maps are
punted to <a class="reference internal" href="expression.html#designing-the-expression-component"><span class="std std-ref">Designing the Expression Component</span></a>.</p></li>
</ul>
</dd>
</dl>
</section>
</section>
<section id="id1">
<h2>Sparsity Design<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<figure class="align-center" id="id2">
<span id="fig-sparsity"></span><img alt="../../_images/sparsity.png" src="../../_images/sparsity.png" />
<figcaption>
<p><span class="caption-number">Fig. 8 </span><span class="caption-text">The major classes underlying the sparsity component of TensorWrapper.</span><a class="headerlink" href="#id2" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#fig-sparsity"><span class="std std-numref">Fig. 8</span></a> shows the main components of TensorWrapper’s sparsity
component. From considerations <span class="xref std std-ref">sparse_element_sparsity</span> and
<span class="xref std std-ref">sparse_block_sparsity</span> we know that we expect users to specify sparsity in
one of two ways. TensorWrapper represents each of these ways with its own
container (respectively <code class="docutils literal notranslate"><span class="pre">Element</span></code> and <code class="docutils literal notranslate"><span class="pre">Block</span></code>). Ultimately these
descriptions all contain the same information (whether pieces of a tensor are
zero or not), just with different representations optimized for the various
limits. In an attempt to treat these representations consistently, and to
introduce code factorization, we have introduced a common base class
<code class="docutils literal notranslate"><span class="pre">Sparsity</span></code>.</p>
<p>From the <span class="xref std std-ref">sparse_dual_problem</span> consideration we know that the user may
wish to fill these containers either with the zero elements of the tensor or
with the non-zero elements of the tensor. We thus introduce two strong types
<code class="docutils literal notranslate"><span class="pre">Zero</span></code> and <code class="docutils literal notranslate"><span class="pre">Nonzero</span></code> which are templated on the container type.</p>
<p>For determining the sparsity of an operation we introduce the
<code class="docutils literal notranslate"><span class="pre">IndexedSparsity</span></code> class. Like the other indexed quantities,
<code class="docutils literal notranslate"><span class="pre">IndexedSparsity</span></code> allows sparsity objects to be combined using Einstein
notation.</p>
</section>
<section id="proposed-apis">
<h2>Proposed APIs<a class="headerlink" href="#proposed-apis" title="Permalink to this headline"></a></h2>
<section id="declaring-an-element-object">
<h3>Declaring an Element Object<a class="headerlink" href="#declaring-an-element-object" title="Permalink to this headline"></a></h3>
<p>Conceptually the simplest sparsity is elemental, which is represented by the
<code class="docutils literal notranslate"><span class="pre">Element</span></code> class. Declaring a tensor has elemental symmetry requires the
shape of the tensor and the zero/non-zero elements. By default <code class="docutils literal notranslate"><span class="pre">Element</span></code>
assumes that the provided indices are for non-zero elements, you need to create
<code class="docutils literal notranslate"><span class="pre">Nonzero&lt;Element&gt;</span></code> objects to denote that the indices are actually for the
non-zero elements:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// A null sparsity object (no shape, no elements, no sparsity)</span>
<span class="n">Element</span><span class="w"> </span><span class="n">enull</span><span class="p">;</span><span class="w"></span>

<span class="c1">// Sparsity for a scalar which is zero</span>
<span class="n">Element</span><span class="w"> </span><span class="nf">e0</span><span class="p">(</span><span class="n">Shape</span><span class="p">{},</span><span class="w"> </span><span class="p">{});</span><span class="w"></span>

<span class="c1">// Sparsity for a scalar which is non-zero</span>
<span class="n">Element</span><span class="w"> </span><span class="nf">zero0</span><span class="p">(</span><span class="n">Shape</span><span class="p">{},</span><span class="w"> </span><span class="p">{{}});</span><span class="w"></span>

<span class="c1">// Sparsity for 10 element vector with all zero elements</span>
<span class="n">Element</span><span class="w"> </span><span class="nf">zero1</span><span class="p">(</span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">},</span><span class="w"> </span><span class="p">{});</span><span class="w"></span>

<span class="c1">// Sparsity for a 10 element vector with non-zero elements 3,5,7</span>
<span class="n">Element</span><span class="w"> </span><span class="nf">e1</span><span class="p">(</span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">});</span><span class="w"></span>

<span class="c1">// Sparsity for a 10 by 20 matrix with non-zero elements: (1,2), (2,3), and</span>
<span class="c1">// (3,4)</span>
<span class="n">Element</span><span class="w"> </span><span class="nf">e2</span><span class="p">(</span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">},</span><span class="w"> </span><span class="p">{{</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">}});</span><span class="w"></span>

<span class="c1">// Sparsity for a 10 by 20 by 30 rank 3 tensor with non-zero elements:</span>
<span class="c1">// (1,2,3) and (2,3,4)</span>
<span class="n">Element</span><span class="w"> </span><span class="nf">e3</span><span class="p">(</span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">},</span><span class="w"> </span><span class="p">{{</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">}});</span><span class="w"></span>

<span class="c1">// Sparsity for a rank 4 tensor totally symmetric tensor with non-zero</span>
<span class="c1">// elements (1,2,3,4), (2,3,4,5), and (3,4,5,6)</span>
<span class="n">Element</span><span class="w"> </span><span class="nf">e4</span><span class="p">(</span><span class="w"></span>
<span class="w">   </span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span><span class="w"> </span><span class="mi">40</span><span class="p">},</span><span class="w"></span>
<span class="w">   </span><span class="p">{{</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">}},</span><span class="w"></span>
<span class="w">   </span><span class="n">TotallySymmetric</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="w"></span>
<span class="p">);</span><span class="w"></span>

<span class="c1">// To instead specify where the zeros are we use the Zero class template.</span>
<span class="c1">// This makes a 10 element vector where elements 3, 5, and 7 are zero:</span>
<span class="n">Zero</span><span class="o">&lt;</span><span class="n">Element</span><span class="o">&gt;</span><span class="w"> </span><span class="n">e1_0</span><span class="p">(</span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">});</span><span class="w"></span>

<span class="c1">// N.B. Declarations of Nonzero&lt;Element&gt; objects are also allowed and are</span>
<span class="c1">// equivalent to just declaring Element objects, e.g. an equivalent way of</span>
<span class="c1">// specifying e2 is by:</span>
<span class="n">Nonzero</span><span class="o">&lt;</span><span class="n">Element</span><span class="o">&gt;</span><span class="w"> </span><span class="n">e2_2</span><span class="p">(</span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">},</span><span class="w"> </span><span class="p">{{</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">}});</span><span class="w"></span>

<span class="c1">// Shapes can be JaggedShape. This is the sparsity for a 3 row jagged matrix</span>
<span class="c1">// with columns of length 10, 20, and 30, where elements (0,3), (1,2), and</span>
<span class="c1">// (2,4) are non-zero.</span>
<span class="n">Element</span><span class="w"> </span><span class="nf">je2</span><span class="p">(</span><span class="w"></span>
<span class="w">   </span><span class="n">JaggedShape</span><span class="p">{</span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">},</span><span class="w"> </span><span class="n">Shape</span><span class="p">{</span><span class="mi">20</span><span class="p">},</span><span class="w"> </span><span class="n">Shape</span><span class="p">{</span><span class="mi">30</span><span class="p">}},</span><span class="w"></span>
<span class="w">   </span><span class="p">{{</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">}}</span><span class="w"></span>
<span class="p">);</span><span class="w"></span>

<span class="c1">// Shapes can also be nested, element indices are flattened (if you don&#39;t</span>
<span class="c1">// want to flatten them use a sparse map). This is the same sparsity as je2</span>
<span class="c1">// except the corresponding tensor is now being thought of as a vector of</span>
<span class="c1">// vectors instead of a jagged matrix</span>
<span class="n">Element</span><span class="w"> </span><span class="nf">je1_1</span><span class="p">(</span><span class="w"></span>
<span class="w">   </span><span class="n">Nested</span><span class="o">&lt;</span><span class="n">JaggedShape</span><span class="o">&gt;</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span><span class="n">JaggedShape</span><span class="p">{</span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">},</span><span class="w"> </span><span class="n">Shape</span><span class="p">{</span><span class="mi">20</span><span class="p">},</span><span class="w"> </span><span class="n">Shape</span><span class="p">{</span><span class="mi">30</span><span class="p">}}),</span><span class="w"></span>
<span class="w">   </span><span class="p">{{</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">}}</span><span class="w"></span>
<span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>Initializer lists are nice for tutorials, but we expect most users will
actually initialize sparsity objects from containers filled at runtime. For
example:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">/// Type Element uses</span>
<span class="k">using</span><span class="w"> </span><span class="n">size_type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Element</span><span class="o">::</span><span class="n">size_type</span><span class="p">;</span><span class="w"></span>

<span class="c1">// For a rank r tensor each index has r components. We will pass each index</span>
<span class="c1">// as a std::vector&lt;size_type&gt;, thus to provide a list of indices we need</span>
<span class="c1">// a vector of vectors.</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">size_type</span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="n">non_zeros</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_non_zeros</span><span class="p">();</span><span class="w"></span>

<span class="c1">// Sparsity for a 10 by 20 by 30 by 40 by 50 rank 5 tensor with non-zero</span>
<span class="c1">// elements specified by &quot;non_zeros&quot; instance.</span>
<span class="n">Element</span><span class="w"> </span><span class="nf">e5</span><span class="p">(</span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span><span class="w"> </span><span class="mi">40</span><span class="p">,</span><span class="w"> </span><span class="mi">50</span><span class="p">},</span><span class="w"> </span><span class="n">non_zeros</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="declaring-a-block-object">
<h3>Declaring a Block Object<a class="headerlink" href="#declaring-a-block-object" title="Permalink to this headline"></a></h3>
<p>After element sparsity, block sparsity is the next simplest. Block sparsity is
represented by the <code class="docutils literal notranslate"><span class="pre">Block</span></code> class. <code class="docutils literal notranslate"><span class="pre">Block</span></code> objects are created similar to
<code class="docutils literal notranslate"><span class="pre">Element</span></code> objects except that instead of providing indices we provide the
sub-shapes which are non-zero:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Null block object (no shape, no blocks, no sparsity)</span>
<span class="n">Block</span><span class="w"> </span><span class="n">bnull</span><span class="p">;</span><span class="w"></span>

<span class="c1">// Sparsity for a zero scalar</span>
<span class="n">Block</span><span class="w"> </span><span class="nf">b0</span><span class="p">(</span><span class="n">Shape</span><span class="p">{},</span><span class="w"> </span><span class="p">{})</span><span class="w"></span>

<span class="c1">// Sparsity for a non-zero scalar</span>
<span class="n">Block</span><span class="w"> </span><span class="n">zero0</span><span class="p">(</span><span class="n">Shape</span><span class="p">{},</span><span class="w"> </span><span class="p">{</span><span class="n">Shape</span><span class="p">{}});</span><span class="w"></span>

<span class="c1">// Sparsity for 10 element vector with non-zero elements: 1, 3, 4, 5, and 6.</span>
<span class="n">Shape</span><span class="w"> </span><span class="n">s1</span><span class="p">{</span><span class="mi">10</span><span class="p">};</span><span class="w"></span>
<span class="n">Block</span><span class="w"> </span><span class="nf">b1</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="n">s1</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">}),</span><span class="w"> </span><span class="n">s1</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">7</span><span class="p">})});</span><span class="w"></span>

<span class="c1">// Sparsity for a 10 by 20 matrix where the diagonal 5 by 10 blocks are</span>
<span class="c1">// non-zero</span>
<span class="n">Shape</span><span class="w"> </span><span class="n">s2</span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">};</span><span class="w"></span>
<span class="n">Block</span><span class="w"> </span><span class="nf">b2</span><span class="p">(</span><span class="n">s2</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="n">s2</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">}),</span><span class="w"> </span><span class="n">s2</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">}));</span><span class="w"></span>

<span class="c1">// Sparsity for a 10 by 20 by 30 rank 3 tensor with two non-zero blocks:</span>
<span class="n">Shape</span><span class="w"> </span><span class="n">s3</span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">};</span><span class="w"></span>
<span class="n">Block</span><span class="w"> </span><span class="nf">b3</span><span class="p">(</span><span class="w"></span>
<span class="w">   </span><span class="n">s3</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="n">s3</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">}),</span><span class="w"> </span><span class="n">s3</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">})</span><span class="w"></span>
<span class="p">);</span><span class="w"></span>

<span class="c1">// Shapes can be JaggedShape</span>
<span class="n">JaggedShape</span><span class="w"> </span><span class="n">js2</span><span class="p">{</span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">},</span><span class="w"> </span><span class="n">Shape</span><span class="p">{</span><span class="mi">20</span><span class="p">}};</span><span class="w"></span>
<span class="n">Block</span><span class="w"> </span><span class="nf">jb2</span><span class="p">(</span><span class="n">js2</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="n">js2</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">}),</span><span class="w"> </span><span class="n">js2</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">9</span><span class="p">})});</span><span class="w"></span>

<span class="c1">// or Nested&lt;T&gt;</span>
<span class="n">Nested</span><span class="o">&lt;</span><span class="n">Shape</span><span class="o">&gt;</span><span class="w"> </span><span class="n">s11</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">});</span><span class="w"></span>
<span class="n">Block</span><span class="w"> </span><span class="nf">b11</span><span class="p">(</span><span class="n">s11</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="n">s11</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">}),</span><span class="w"> </span><span class="n">s11</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">})});</span><span class="w"></span>
</pre></div>
</div>
<p>Analogous to <code class="docutils literal notranslate"><span class="pre">Element</span></code>, one can specify the zero blocks by using
<code class="docutils literal notranslate"><span class="pre">Zero&lt;Block&gt;</span></code> and the constructors also accept iterators over lists of shapes.</p>
</section>
<section id="declaring-a-sparsity-object-with-norms">
<h3>Declaring a Sparsity Object with Norms<a class="headerlink" href="#declaring-a-sparsity-object-with-norms" title="Permalink to this headline"></a></h3>
<p>Effective sparsity is conceptually a variation on block sparsity where instead
of specifying whether each block is/isn’t zero, we instead specify “how zero” a
block actually is. Put another way, <code class="docutils literal notranslate"><span class="pre">Block</span></code> objects are <code class="docutils literal notranslate"><span class="pre">Norm</span></code> objects
where zero blocks have a norm of zero and and non-zero blocks have norms of
infinity. Declaring a <code class="docutils literal notranslate"><span class="pre">Norm</span></code> object requires: the shape of the tensor, the
norms of the blocks, and the effective zero threshold:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="c1">// Null Norm object (no shape, no sparsity)</span>
<span class="n">Norm</span><span class="w"> </span><span class="n">nnull</span><span class="p">;</span><span class="w"></span>

<span class="c1">// Norm object for a scalar</span>
<span class="n">Norm</span><span class="w"> </span><span class="nf">n0</span><span class="p">(</span><span class="n">Shape</span><span class="p">{},</span><span class="w"> </span><span class="n">Tensor</span><span class="p">{</span><span class="n">norm</span><span class="p">});</span><span class="w"></span>

<span class="c1">// Norm object for a 10 element vector</span>
<span class="n">Norm</span><span class="w"> </span><span class="nf">n1</span><span class="p">(</span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">},</span><span class="w"> </span><span class="n">Tensor</span><span class="p">{</span><span class="n">norm</span><span class="p">}));</span><span class="w"></span>

<span class="c1">// Norm object for a 5 by 20 Matrix viewed as a vector of vectors</span>
<span class="n">Nested</span><span class="o">&lt;</span><span class="n">Shape</span><span class="o">&gt;</span><span class="w"> </span><span class="n">s1_1</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">},</span><span class="w"> </span><span class="n">Shape</span><span class="p">{</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">});;</span><span class="w"></span>
<span class="n">Norm</span><span class="w"> </span><span class="nf">n2</span><span class="p">(</span><span class="n">s1_1</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">{</span><span class="n">norm0</span><span class="p">,</span><span class="w"> </span><span class="n">norm1</span><span class="p">,</span><span class="w"> </span><span class="n">norm2</span><span class="p">,</span><span class="w"> </span><span class="n">norm3</span><span class="p">,</span><span class="w"> </span><span class="n">norm4</span><span class="p">},</span><span class="w"> </span><span class="mf">10E-10</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Vector of matrices example</span>
<span class="n">Nested</span><span class="o">&lt;</span><span class="n">Shape</span><span class="o">&gt;</span><span class="w"> </span><span class="n">s1_2</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="n">Shape</span><span class="p">{</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">,</span><span class="w"> </span><span class="mi">30</span><span class="p">});</span><span class="w"></span>
<span class="n">Norm</span><span class="w"> </span><span class="nf">n1_2</span><span class="p">(</span><span class="n">s1_2</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">{</span><span class="n">norm0</span><span class="p">,</span><span class="w"> </span><span class="n">norm1</span><span class="p">,</span><span class="w"> </span><span class="n">norm2</span><span class="p">,</span><span class="w"> </span><span class="n">norm3</span><span class="p">,</span><span class="w"> </span><span class="n">norm4</span><span class="p">});</span><span class="w"></span>

<span class="c1">// Matrix of vectors example</span>
<span class="n">Nested</span><span class="o">&lt;</span><span class="n">Shape</span><span class="o">&gt;</span><span class="w"> </span><span class="n">s2_1</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">},</span><span class="w"> </span><span class="n">Shape</span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">});</span><span class="w"></span>
<span class="n">Tensor</span><span class="w"> </span><span class="n">t</span><span class="p">{{</span><span class="n">norm00</span><span class="p">,</span><span class="w"> </span><span class="n">norm01</span><span class="p">,</span><span class="w"> </span><span class="n">norm02</span><span class="p">},</span><span class="w"></span>
<span class="w">         </span><span class="p">{</span><span class="n">norm10</span><span class="p">,</span><span class="w"> </span><span class="n">norm11</span><span class="p">,</span><span class="w"> </span><span class="n">norm12</span><span class="p">},</span><span class="w"></span>
<span class="w">         </span><span class="p">{</span><span class="n">norm20</span><span class="p">,</span><span class="w"> </span><span class="n">norm21</span><span class="p">,</span><span class="w"> </span><span class="n">norm22</span><span class="p">}};</span><span class="w"></span>
<span class="n">Norm</span><span class="w"> </span><span class="nf">n2_1</span><span class="p">(</span><span class="n">s2_1</span><span class="p">,</span><span class="w"> </span><span class="n">t</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Jagged matrix with three rows</span>
<span class="n">JaggedShape</span><span class="w"> </span><span class="n">js2</span><span class="p">{</span><span class="n">Shape</span><span class="p">{</span><span class="mi">10</span><span class="p">},</span><span class="w"> </span><span class="n">Shape</span><span class="p">{</span><span class="mi">20</span><span class="p">},</span><span class="w"> </span><span class="n">Shape</span><span class="p">{</span><span class="mi">30</span><span class="p">}};</span><span class="w"></span>
<span class="n">Norm</span><span class="w"> </span><span class="nf">jn2</span><span class="p">(</span><span class="n">js2</span><span class="p">,</span><span class="w"> </span><span class="n">Tensor</span><span class="p">{</span><span class="n">norm0</span><span class="p">,</span><span class="w"> </span><span class="n">norm1</span><span class="p">,</span><span class="w"> </span><span class="n">norm2</span><span class="p">});</span><span class="w"></span>
</pre></div>
</div>
<p>As shown for <code class="docutils literal notranslate"><span class="pre">n0</span></code>, <code class="docutils literal notranslate"><span class="pre">Norm</span></code> works with <code class="docutils literal notranslate"><span class="pre">Shape</span></code> objects, but only supports a
single norm (that of the entire tensor) in such cases. Generally speaking,
<code class="docutils literal notranslate"><span class="pre">Norm</span></code> is much more useful for tensors declared with <code class="docutils literal notranslate"><span class="pre">JaggedShape</span></code>,
<code class="docutils literal notranslate"><span class="pre">Nested&lt;Shape&gt;</span></code>, or <code class="docutils literal notranslate"><span class="pre">Nested&lt;JaggedShape&gt;</span></code> shapes. As also shown, the norms
are provided as <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> objects. The rank of the provided tensor is always
zero if the <code class="docutils literal notranslate"><span class="pre">Norm</span></code> object is based off of a <code class="docutils literal notranslate"><span class="pre">Shape</span></code> object and it is the
rank of the outer layer for <code class="docutils literal notranslate"><span class="pre">JaggedShape</span></code> and <code class="docutils literal notranslate"><span class="pre">Nested</span></code> objects. Finally,
as shown in constructing <code class="docutils literal notranslate"><span class="pre">n2</span></code> the user may provide a custom zero (default is
machine precision).</p>
</section>
<section id="composing-sparsity-objects">
<h3>Composing Sparsity Objects<a class="headerlink" href="#composing-sparsity-objects" title="Permalink to this headline"></a></h3>
<figure class="align-center" id="id3">
<span id="fig-composing-sparsity"></span><img alt="../../_images/composing_sparsity.png" src="../../_images/composing_sparsity.png" />
<figcaption>
<p><span class="caption-number">Fig. 9 </span><span class="caption-text">An example of combining the sparsities of two 10 by 20 matrices.</span><a class="headerlink" href="#id3" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#fig-composing-sparsity"><span class="std std-numref">Fig. 9</span></a> shows two of the basic tensor operations for
two matrices <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{B}\)</span>, each of which is 10 by 20. In code:</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">Shape</span><span class="w"> </span><span class="n">shape</span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">};</span><span class="w"></span>

<span class="n">Element</span><span class="w"> </span><span class="nf">sparse_a</span><span class="p">(</span><span class="w"></span>
<span class="w">   </span><span class="n">shape</span><span class="p">,</span><span class="w"> </span><span class="p">{{</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="mi">17</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">7</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">8</span><span class="p">,</span><span class="mi">13</span><span class="p">}}</span><span class="w"></span>
<span class="p">);</span><span class="w"></span>
<span class="n">Block</span><span class="w"> </span><span class="nf">sparse_b</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span><span class="w"></span>
<span class="w">   </span><span class="p">{</span><span class="n">shape</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">}),</span><span class="w"></span>
<span class="w">    </span><span class="n">shape</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">}),</span><span class="w"></span>
<span class="w">    </span><span class="n">shape</span><span class="p">.</span><span class="n">slice</span><span class="p">({</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">15</span><span class="p">})}</span><span class="w"></span>
<span class="p">);</span><span class="w"></span>

<span class="c1">// Addition</span>
<span class="n">Sparsity</span><span class="w"> </span><span class="n">c</span><span class="p">;</span><span class="w"></span>
<span class="n">c</span><span class="p">(</span><span class="s">&quot;i,j&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">(</span><span class="s">&quot;i,j&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">b</span><span class="p">(</span><span class="s">&quot;i,j&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">assert</span><span class="p">(</span><span class="n">c</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">a</span><span class="p">.</span><span class="k">union</span><span class="p">(</span><span class="n">b</span><span class="p">));</span><span class="w"></span>

<span class="c1">// Contraction</span>
<span class="n">c</span><span class="p">(</span><span class="s">&quot;i,j&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">(</span><span class="s">&quot;i,k&quot;</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">b</span><span class="p">(</span><span class="s">&quot;k,j&quot;</span><span class="p">);</span><span class="w"></span>
<span class="n">Element</span><span class="w"> </span><span class="nf">corr</span><span class="p">(</span><span class="n">Shape</span><span class="p">{</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">},</span><span class="w"></span>
<span class="w">   </span><span class="p">{{</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="mi">8</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="mi">13</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">3</span><span class="p">,</span><span class="mi">12</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">4</span><span class="p">,</span><span class="mi">11</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">7</span><span class="p">,</span><span class="mi">13</span><span class="p">},</span><span class="w"></span>
<span class="w">    </span><span class="p">{</span><span class="mi">8</span><span class="p">,</span><span class="mi">0</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">8</span><span class="p">,</span><span class="mi">10</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">13</span><span class="p">,</span><span class="mi">7</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">18</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">18</span><span class="p">,</span><span class="mi">12</span><span class="p">}}</span><span class="w"></span>
<span class="p">);</span><span class="w"></span>
<span class="n">assert</span><span class="p">(</span><span class="n">c</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">corr</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
<p>Composing of sparsity objects follows the same API as composing with other
TensorWrapper objects, largely for consistency.</p>
</section>
<section id="basic-operations">
<h3>Basic Operations<a class="headerlink" href="#basic-operations" title="Permalink to this headline"></a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This section will be filled out more as the operations needed are better
understood.</p>
</div>
<p>All sparse containers inherit from the <code class="docutils literal notranslate"><span class="pre">Sparsity</span></code> class, which also defines
the basic API for many sparsity operations.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="n">Sparsity</span><span class="w"> </span><span class="n">s</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_tensor_sparsity</span><span class="p">();</span><span class="w"></span>
<span class="n">Sparsity</span><span class="w"> </span><span class="n">other_sparsity</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_other_sparsity</span><span class="p">();</span><span class="w"></span>
<span class="c1">// Checks if element (0,1) is 0</span>
<span class="k">auto</span><span class="w"> </span><span class="n">is_zero</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="p">.</span><span class="n">is_zero</span><span class="p">({</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">});</span><span class="w"></span>

<span class="c1">// Checks if a block starting with (0,1) and ending with (10, 10) is all 0</span>
<span class="n">is_zero</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="p">.</span><span class="n">is_zero</span><span class="p">({</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">});</span><span class="w"></span>

<span class="c1">// Checks if element (0,1) is non-zero</span>
<span class="k">auto</span><span class="w"> </span><span class="n">is_nonzero</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="p">.</span><span class="n">is_nonzero</span><span class="p">({</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">});</span><span class="w"></span>

<span class="c1">// Checks if the block starting with (0,1) and ending with (10, 10) has any</span>
<span class="c1">// non-zero elements</span>
<span class="n">is_nonzero</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="p">.</span><span class="n">is_nonzero</span><span class="p">({</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">},</span><span class="w"> </span><span class="p">{</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">});</span><span class="w"></span>

<span class="c1">// Compute the sparsity (# of zero elements/total number of elements)</span>
<span class="k">auto</span><span class="w"> </span><span class="n">sparsity</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="p">.</span><span class="n">sparsity</span><span class="p">();</span><span class="w"></span>

<span class="c1">// Create a new sparsity object with the same total shape and the non-zero</span>
<span class="c1">// elements from s and other_sparsity</span>
<span class="k">auto</span><span class="w"> </span><span class="n">the_union</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="p">.</span><span class="n">nonzero_union</span><span class="p">(</span><span class="n">other_sparsity</span><span class="p">);</span><span class="w"></span>

<span class="c1">// Create a new sparsity object with the same total shape and the zero</span>
<span class="c1">// elements from z and other_sparsity</span>
<span class="n">the_union</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">s</span><span class="p">.</span><span class="n">zero_union</span><span class="p">(</span><span class="n">other_sparsity</span><span class="p">);</span><span class="w"></span>
</pre></div>
</div>
</section>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline"></a></h2>
<dl class="simple">
<dt><span class="xref std std-ref">sparse_element_sparsity</span></dt><dd><p>Specifying a tensor is element sparse is done by making an instance of
<code class="docutils literal notranslate"><span class="pre">Element</span></code>.</p>
</dd>
<dt><span class="xref std std-ref">sparse_block_sparsity</span></dt><dd><p>Specifying a tensor is block sparse is done by making an instance of
<code class="docutils literal notranslate"><span class="pre">Block</span></code>.</p>
</dd>
<dt><span class="xref std std-ref">sparse_effective_sparsity</span></dt><dd><p>Exploiting effective sparsity is done with the <code class="docutils literal notranslate"><span class="pre">Norm</span></code> class.</p>
</dd>
<dt><span class="xref std std-ref">sparse_operational_sparsity</span></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">Sparsity</span></code> objects can be composed using Einstein notation. Sparsity
can then be propagated to the result by carrying out the expressed operation.</p>
</dd>
<dt><span class="xref std std-ref">sparse_effective_operational_sparsity</span></dt><dd><p>Key to this effort is a way to estimate the result without fully computing
it. Norms, are a natural solution and have been added as an optional member
to the <code class="docutils literal notranslate"><span class="pre">Sparsity</span></code> class.</p>
</dd>
<dt><span class="xref std std-ref">sparse_dual_problem</span></dt><dd><p>To account for the fact that sometimes it is easier to specify the zeros
rather than the non-zeros, we have respectively introduced the <code class="docutils literal notranslate"><span class="pre">Zero</span></code> and
<code class="docutils literal notranslate"><span class="pre">Nonzero</span></code> strong types.</p>
</dd>
<dt><span class="xref std std-ref">sparse_symmetry</span></dt><dd><p>The <code class="docutils literal notranslate"><span class="pre">Sparsity</span></code> base class holds a <code class="docutils literal notranslate"><span class="pre">Symmetry</span></code> object and can use it to
only store the symmetry unique sparsity information/generate the symmetry
redundant information.</p>
</dd>
<dt><span class="xref std std-ref">sparse_basic_operations</span></dt><dd><p>Basic operations have been factored out into the <code class="docutils literal notranslate"><span class="pre">Sparsity</span></code> base class.
The exact API</p>
</dd>
</dl>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="symmetry.html" class="btn btn-neutral float-left" title="Designing the Symmetry Component" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="layout.html" class="btn btn-neutral float-right" title="Designing the Layout Component" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, NWChemEx Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>